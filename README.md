# RLNAS for Autoencoder-based Anomaly Detection in Time Series Data

Implementation of Neural Architecture Search for automated anomaly detection in IoT and smart building time series data.

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-1.8+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ¯ Overview

This project implements a Reinforcement Learning-based Neural Architecture Search (RLNAS) framework that automatically discovers optimal autoencoder architectures for detecting anomalies in time series data.

### Key Features
- ğŸ¤– **Automated Architecture Design**: Uses RL to automatically design neural networks
- ğŸ“Š **Time Series Anomaly Detection**: Specialized for IoT and smart building data
- ğŸ¯ **High Performance**: Achieves 97.6% precision with minimal false alarms
- ğŸ”§ **Flexible Framework**: Works with various time series datasets

## ğŸ“ˆ Results

Our NAS framework discovered an architecture achieving:
- **F1-Score**: 87.86%
- **Precision**: 97.62% (very few false alarms!)
- **Recall**: 79.87%

### Discovered Architecture
```
Block 1: Conv(16 filters, kernel=15) â†’ AvgPool(7) â†’ BatchNorm
Block 2: Conv(16 filters, kernel=15) â†’ BatchNorm
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (optional but recommended)

### Installation

1. Clone the repository:
```bash
git clone git@github.com:progami/anamoly-detection.git
cd anamoly-detection
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

### Data Preparation

1. Place your time series data in `dataset/weather_data/` 
2. Generate synthetic anomalies:
```bash
python prepare_data.py
```

This creates:
- Training data (clean, no anomalies)
- Test data (20% contaminated with anomalies)
- Separate datasets for each feature (Temperature, Humidity, Pressure)

### Running NAS

Train the Neural Architecture Search to find optimal architectures:

```bash
# For Temperature anomaly detection
python main.py --train_dataset_path dataset/synth_ts_data/train_IHAMPS1_Temperature_C.csv \
               --test_dataset_path dataset/synth_ts_data/test_IHAMPS1_Temperature_C.csv \
               --output_file results/nas_results.txt
```

The NAS will:
- Evaluate 200 different architectures
- Use reinforcement learning to guide the search
- Output the best architecture and its performance

### Visualizing Results

Use the provided Jupyter notebooks for visualization and analysis:

```bash
jupyter notebook notebooks/autoencoder_based_time_series_anomaly_detection.ipynb
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/                          # Configuration files
â”‚   â”œâ”€â”€ autoencoder_params.py       # Training parameters
â”‚   â”œâ”€â”€ controller_params.py        # RL controller settings
â”‚   â””â”€â”€ search_space.py             # Architecture search space
â”œâ”€â”€ dataset/                         # Data directory
â”‚   â”œâ”€â”€ weather_data/               # Raw weather data
â”‚   â”œâ”€â”€ gen_anomalies/              # Generated anomalies
â”‚   â””â”€â”€ synth_ts_data/              # Train/test datasets
â”œâ”€â”€ models/                          # Model definitions
â”‚   â”œâ”€â”€ autoencoder.py              # Autoencoder architecture
â”‚   â””â”€â”€ controller.py               # RL controller network
â”œâ”€â”€ notebooks/                       # Jupyter notebooks
â”‚   â””â”€â”€ autoencoder_based_time_series_anomaly_detection.ipynb
â”œâ”€â”€ utils/                           # Utility functions
â”‚   â”œâ”€â”€ data_loaders.py             # Data loading utilities
â”‚   â””â”€â”€ utils.py                    # Helper functions
â”œâ”€â”€ main.py                         # Main NAS training script
â”œâ”€â”€ prepare_data.py                 # Data preparation script
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # This file
```

## ğŸ”§ Configuration

### Search Space Configuration (`config/search_space.py`)
```python
n_episodes = 200        # Number of architectures to try
n_blocks = 2           # Number of blocks in architecture
```

### Training Configuration (`config/autoencoder_params.py`)
```python
epochs = 100           # Training epochs per architecture
batch_size = 32       
learning_rate = 0.001
```

## ğŸ“Š Datasets

The framework works with time series data containing:
- **Features**: Temperature, Humidity, Pressure (or any univariate time series)
- **Window Size**: 100 timesteps
- **Anomaly Types**: Point anomalies, contextual anomalies

### Using Your Own Data

1. Format your data as CSV with columns matching the expected format
2. Place in `dataset/weather_data/`
3. Update `dataset_names` in `prepare_data.py`
4. Run data preparation script

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.